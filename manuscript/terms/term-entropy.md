### Entropy

In information theory defined as "amount of information" a message has or
"unpredictability of information content". The entropy of a cryptosystem is
measured by the size of the keyspace. Larger keyspaces have an increased
entropy and if not flawed by the algorithm itself, harder to break than smaller
ones.
For secure cryptographic operations it is mandatory to not only use random
values as input, they should have also a high entropy. The creation of high
entropy on a computer system is non-trivial and can affect the performance of a
system.

See [11.1 Information Theory of Schneier-1996](#ref-schneier-1996) and Whitewood Inc. on ["Understanding and Managing Entropy"](https://www.blackhat.com/docs/us-15/materials/us-15-Potter-Understanding-And-Managing-Entropy-Usage-wp.pdf) or [SANS "Randomness and Entropy - An Introduction"](https://www.sans.org/reading-room/whitepapers/vpns/randomness-entropy-introduction-874).

Category: Security


